{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Iq_2Wi5XhwCQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlP0PVw41fNJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# HypeParameters\n",
        "input=28*28\n",
        "input_size = input\n",
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "hidden_size = 500\n",
        "batch_size = 128\n",
        "learning_rate = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxkY7Ox_hzWx"
      },
      "outputs": [],
      "source": [
        "#Data-loading\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data',train=True,\n",
        "transform=transforms.ToTensor(),download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data',train=False,\n",
        "transform=transforms.ToTensor(),download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=(train_dataset),\n",
        "batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=(test_dataset) ,\n",
        "batch_size=batch_size,shuffle=False)\n",
        "###########################################\n",
        "def create_datasets(batch_size):\n",
        "# percentage of training set to use as validation\n",
        "  valid_size = 0.15\n",
        "# convert data to torch.FloatTensor\n",
        "  transform = transforms.ToTensor()\n",
        "# choose the training and test datasets\n",
        "  train_data = datasets.FashionMNIST(root='data',train=True,download=True,\n",
        "                              transform=transform)\n",
        "  test_data = datasets.FashionMNIST(root='data',train=False,download=True,\n",
        "                             transform=transform)\n",
        "  # obtain training indices that will be used for validation\n",
        "  num_train = len(train_data)\n",
        "  indices = list(range(num_train))\n",
        "  np.random.shuffle(indices)\n",
        "  split = int(np.floor(valid_size * num_train))\n",
        "  train_idx, valid_idx = indices[split:], indices[:split]\n",
        "  # define samplers for obtaining training and validation batches\n",
        "  train_sampler = SubsetRandomSampler(train_idx)\n",
        "  valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "  # load training data in batches\n",
        "  train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,\n",
        "  sampler=train_sampler,num_workers=0)\n",
        "  # load validation data in batches\n",
        "  valid_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,\n",
        "  sampler=valid_sampler,num_workers=0)\n",
        "  # load test data in batches\n",
        "  test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size,\n",
        "  num_workers=0)\n",
        "  return train_loader, test_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1oJccvOsZWk"
      },
      "outputs": [],
      "source": [
        "# example = iter(train_loader)\n",
        "# example\n",
        "# example_data, example_targ = example.next()\n",
        "# for i in range(6):\n",
        "#   plt.subplot(2,3,i+1)\n",
        "#   plt.imshow(example_data[i][0])\n",
        "#   plt.show()\n",
        "#pick a sample to plot\n",
        "\n",
        "sample = 3\n",
        "image = train_dataset[3][0][0]\n",
        "# plot the sample\n",
        "fig = plt.figure\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjHmPsB6swVh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1ArX3nIs3Lv",
        "outputId": "c4086c96-8e3e-4717-e92d-933b02ded98f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNet(\n",
            "  (l1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (l2): Linear(in_features=500, out_features=250, bias=True)\n",
            "  (l3): Linear(in_features=250, out_features=10, bias=True)\n",
            "  (N): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, math.floor(hidden_size/2))\n",
        "    self.l3 = nn.Linear(math.floor(hidden_size/2), num_classes)\n",
        "    self.N=nn.Softmax()\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.l3(out)\n",
        "    # no activation and no softmax at the end\n",
        "    return out\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y0CoAAkttGOC",
        "outputId": "46e08e9a-543a-4393-c763-63bf3c0769a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.8947812914848328\n",
            "Epoch [1/10], Step [200/469], Loss: 0.7380427122116089\n",
            "Epoch [1/10], Step [300/469], Loss: 0.6428419351577759\n",
            "Epoch [1/10], Step [400/469], Loss: 0.513683021068573\n",
            "Epoch [2/10], Step [100/469], Loss: 0.49215883016586304\n",
            "Epoch [2/10], Step [200/469], Loss: 0.42894595861434937\n",
            "Epoch [2/10], Step [300/469], Loss: 0.360217422246933\n",
            "Epoch [2/10], Step [400/469], Loss: 0.47549620270729065\n",
            "Epoch [3/10], Step [100/469], Loss: 0.5738204121589661\n",
            "Epoch [3/10], Step [200/469], Loss: 0.4235231876373291\n",
            "Epoch [3/10], Step [300/469], Loss: 0.5362973809242249\n",
            "Epoch [3/10], Step [400/469], Loss: 0.3853635787963867\n",
            "Epoch [4/10], Step [100/469], Loss: 0.3558949828147888\n",
            "Epoch [4/10], Step [200/469], Loss: 0.49537286162376404\n",
            "Epoch [4/10], Step [300/469], Loss: 0.35782068967819214\n",
            "Epoch [4/10], Step [400/469], Loss: 0.4016790986061096\n",
            "Epoch [5/10], Step [100/469], Loss: 0.41262832283973694\n",
            "Epoch [5/10], Step [200/469], Loss: 0.32114177942276\n",
            "Epoch [5/10], Step [300/469], Loss: 0.5399298667907715\n",
            "Epoch [5/10], Step [400/469], Loss: 0.5223937630653381\n",
            "Epoch [6/10], Step [100/469], Loss: 0.5086269378662109\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2975493371486664\n",
            "Epoch [6/10], Step [300/469], Loss: 0.3047106862068176\n",
            "Epoch [6/10], Step [400/469], Loss: 0.3679600656032562\n",
            "Epoch [7/10], Step [100/469], Loss: 0.36806753277778625\n",
            "Epoch [7/10], Step [200/469], Loss: 0.361255943775177\n",
            "Epoch [7/10], Step [300/469], Loss: 0.33602985739707947\n",
            "Epoch [7/10], Step [400/469], Loss: 0.33394214510917664\n",
            "Epoch [8/10], Step [100/469], Loss: 0.3637099266052246\n",
            "Epoch [8/10], Step [200/469], Loss: 0.3508680760860443\n",
            "Epoch [8/10], Step [300/469], Loss: 0.29199525713920593\n",
            "Epoch [8/10], Step [400/469], Loss: 0.29626426100730896\n",
            "Epoch [9/10], Step [100/469], Loss: 0.2960127890110016\n",
            "Epoch [9/10], Step [200/469], Loss: 0.35169366002082825\n",
            "Epoch [9/10], Step [300/469], Loss: 0.31019824743270874\n",
            "Epoch [9/10], Step [400/469], Loss: 0.3305296301841736\n",
            "Epoch [10/10], Step [100/469], Loss: 0.29576554894447327\n",
            "Epoch [10/10], Step [200/469], Loss: 0.3312704861164093\n",
            "Epoch [10/10], Step [300/469], Loss: 0.3593493103981018\n",
            "Epoch [10/10], Step [400/469], Loss: 0.24861600995063782\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00001)\n",
        "Loss=[]\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # origin shape: [100, 1, 28, 28]\n",
        "    # resized: [100, 784]\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    Loss.append(loss.item())\n",
        "    if (i+1) % 100 == 0:\n",
        "      print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item()}')\n",
        "\n",
        "plt.plot(Loss)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvOjV2Yu_AW2"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    # max returns (value ,index)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network on the 10000 test i```mages: {acc} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPVFu3X5UQJ-",
        "outputId": "213078f1-5358-4a68-8340-c5ae371c753e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet(\n",
            "  (l1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (l2): Linear(in_features=500, out_features=250, bias=True)\n",
            "  (BN): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (D0): Dropout(p=0.05, inplace=False)\n",
            "  (D1): Dropout(p=0.15, inplace=False)\n",
            "  (l3): Linear(in_features=250, out_features=20, bias=True)\n",
            "  (BN2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (l4): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (N): Softmax(dim=None)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "del model\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, math.floor(hidden_size/2))\n",
        "    self.BN= nn.BatchNorm1d(math.floor(hidden_size/2))\n",
        "    self.D0=nn.Dropout(0.05)\n",
        "    self.D1=nn.Dropout(0.15)\n",
        "    self.l3 = nn.Linear(math.floor(hidden_size/2), num_classes*2)\n",
        "    self.BN2= nn.BatchNorm1d(num_classes*2)\n",
        "    self.l4 = nn.Linear(num_classes*2, num_classes)\n",
        "    self.N=nn.Softmax()\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out= self.D0(out)\n",
        "    out = self.l2(out)\n",
        "    out= self.BN(out)\n",
        "    out = self.relu(out)\n",
        "    out= self.D1(out)\n",
        "    out = self.l3(out)\n",
        "    out = self.relu(out)\n",
        "    out= self.BN2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.l4(out)\n",
        "    # no activation and no softmax at the end\n",
        "    return out\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7XrA8GvCtj2_",
        "outputId": "ec09804c-0706-4a6c-bc36-bcb7cf2d16b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 1.4218800067901611\n",
            "Epoch [1/10], Step [200/469], Loss: 1.328701138496399\n",
            "Epoch [1/10], Step [300/469], Loss: 1.1972815990447998\n",
            "Epoch [1/10], Step [400/469], Loss: 1.1386239528656006\n",
            "Epoch [2/10], Step [100/469], Loss: 0.9976623058319092\n",
            "Epoch [2/10], Step [200/469], Loss: 0.9992952942848206\n",
            "Epoch [2/10], Step [300/469], Loss: 0.8878344297409058\n",
            "Epoch [2/10], Step [400/469], Loss: 0.744052529335022\n",
            "Epoch [3/10], Step [100/469], Loss: 0.659353494644165\n",
            "Epoch [3/10], Step [200/469], Loss: 0.7189027667045593\n",
            "Epoch [3/10], Step [300/469], Loss: 0.5576114058494568\n",
            "Epoch [3/10], Step [400/469], Loss: 0.6361163258552551\n",
            "Epoch [4/10], Step [100/469], Loss: 0.6345592737197876\n",
            "Epoch [4/10], Step [200/469], Loss: 0.5662624835968018\n",
            "Epoch [4/10], Step [300/469], Loss: 0.4833127558231354\n",
            "Epoch [4/10], Step [400/469], Loss: 0.44945552945137024\n",
            "Epoch [5/10], Step [100/469], Loss: 0.47366857528686523\n",
            "Epoch [5/10], Step [200/469], Loss: 0.44342800974845886\n",
            "Epoch [5/10], Step [300/469], Loss: 0.4792379140853882\n",
            "Epoch [5/10], Step [400/469], Loss: 0.4135746657848358\n",
            "Epoch [6/10], Step [100/469], Loss: 0.26972275972366333\n",
            "Epoch [6/10], Step [200/469], Loss: 0.3937090337276459\n",
            "Epoch [6/10], Step [300/469], Loss: 0.3648633062839508\n",
            "Epoch [6/10], Step [400/469], Loss: 0.3748798370361328\n",
            "Epoch [7/10], Step [100/469], Loss: 0.2566990852355957\n",
            "Epoch [7/10], Step [200/469], Loss: 0.27366092801094055\n",
            "Epoch [7/10], Step [300/469], Loss: 0.24431036412715912\n",
            "Epoch [7/10], Step [400/469], Loss: 0.32897520065307617\n",
            "Epoch [8/10], Step [100/469], Loss: 0.24407893419265747\n",
            "Epoch [8/10], Step [200/469], Loss: 0.25892192125320435\n",
            "Epoch [8/10], Step [300/469], Loss: 0.4507015645503998\n",
            "Epoch [8/10], Step [400/469], Loss: 0.331432968378067\n",
            "Epoch [9/10], Step [100/469], Loss: 0.3000344932079315\n",
            "Epoch [9/10], Step [200/469], Loss: 0.2126813530921936\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1755136400461197\n",
            "Epoch [9/10], Step [400/469], Loss: 0.3840770125389099\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1980048567056656\n",
            "Epoch [10/10], Step [200/469], Loss: 0.21452036499977112\n",
            "Epoch [10/10], Step [300/469], Loss: 0.35739365220069885\n",
            "Epoch [10/10], Step [400/469], Loss: 0.3787299692630768\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00001)\n",
        "Loss2=[]\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        outputsval = model(images)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        Loss2.append(loss.item())\n",
        "        if (i+1) % 100 == 0:\n",
        "            \n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item()}')\n",
        "plt.plot(Loss2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSUiTHpHVNLh"
      },
      "outputs": [],
      "source": [
        " # Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples= 0\n",
        "    for images, labels in test_loader:\n",
        "        \n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "    # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "    acc= 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "    #89.18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2jSCFz8VcVt"
      },
      "outputs": [],
      "source": [
        "plt.plot(Loss)\n",
        "plt.plot(Loss2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYBp4b6YVf58"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kgO71omOaQx6"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "G1SjRIvyjqFU"
      },
      "outputs": [],
      "source": [
        "def train_model(model, batch_size, patience, n_epochs):\n",
        "    \n",
        "      # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "  # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "  # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "  # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = []\n",
        "  # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True) \n",
        "    for epoch in range( n_epochs ):\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "        model.train() # prep model for training\n",
        "    #for i, (images, labels) in enumerate(train_loader):\n",
        "        for batch, (data, target) in enumerate(train_loader,1):\n",
        "      # clear the gradients of all optimized variables\n",
        "            data = data.reshape(-1, 28*28).to(device)\n",
        "            target = target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "      # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "      # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "      # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "      # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "        model.eval() # prep model for evaluation\n",
        "        for data, target in valid_loader:\n",
        "            data = data.reshape(-1, 28*28).to(device)\n",
        "            target = target.to(device)\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "          # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "          # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "    # print training/validation statistics\n",
        "    # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        epoch_len = len(str(n_epochs))\n",
        "        print_msg = (f'[{epoch:>{epoch_len+1}}/{n_epochs:>{epoch_len}}] ' +\n",
        "        f'train_loss: {train_loss:.5f} ' +\n",
        "        f'valid_loss: {valid_loss:.5f}')\n",
        "        print(print_msg)\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        # early_stopping needs the validation loss to check if it has decresed,\n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "  # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "    return model, avg_train_losses, avg_valid_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-mRHjlLkazl",
        "outputId": "2eea1dd5-eb0d-4c7b-9325-9033b56bc943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0/20] train_loss: 1.39302 valid_loss: 1.14864\n",
            "Validation loss decreased (inf --> 1.148640).  Saving model ...\n",
            "[  1/20] train_loss: 1.01878 valid_loss: 0.85931\n",
            "Validation loss decreased (1.148640 --> 0.859313).  Saving model ...\n",
            "[  2/20] train_loss: 0.77900 valid_loss: 0.66929\n",
            "Validation loss decreased (0.859313 --> 0.669292).  Saving model ...\n",
            "[  3/20] train_loss: 0.61102 valid_loss: 0.53911\n",
            "Validation loss decreased (0.669292 --> 0.539113).  Saving model ...\n",
            "[  4/20] train_loss: 0.50201 valid_loss: 0.47235\n",
            "Validation loss decreased (0.539113 --> 0.472352).  Saving model ...\n",
            "[  5/20] train_loss: 0.42652 valid_loss: 0.40908\n",
            "Validation loss decreased (0.472352 --> 0.409075).  Saving model ...\n",
            "[  6/20] train_loss: 0.37405 valid_loss: 0.37602\n",
            "Validation loss decreased (0.409075 --> 0.376016).  Saving model ...\n",
            "[  7/20] train_loss: 0.33344 valid_loss: 0.34360\n",
            "Validation loss decreased (0.376016 --> 0.343605).  Saving model ...\n",
            "[  8/20] train_loss: 0.30248 valid_loss: 0.32122\n",
            "Validation loss decreased (0.343605 --> 0.321222).  Saving model ...\n",
            "[  9/20] train_loss: 0.27828 valid_loss: 0.30720\n",
            "Validation loss decreased (0.321222 --> 0.307202).  Saving model ...\n",
            "[ 10/20] train_loss: 0.25860 valid_loss: 0.29778\n",
            "Validation loss decreased (0.307202 --> 0.297784).  Saving model ...\n",
            "[ 11/20] train_loss: 0.24458 valid_loss: 0.30451\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[ 12/20] train_loss: 0.23071 valid_loss: 0.29657\n",
            "Validation loss decreased (0.297784 --> 0.296573).  Saving model ...\n",
            "[ 13/20] train_loss: 0.21756 valid_loss: 0.28764\n",
            "Validation loss decreased (0.296573 --> 0.287635).  Saving model ...\n",
            "[ 14/20] train_loss: 0.20688 valid_loss: 0.29761\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[ 15/20] train_loss: 0.19359 valid_loss: 0.28473\n",
            "Validation loss decreased (0.287635 --> 0.284729).  Saving model ...\n",
            "[ 16/20] train_loss: 0.18814 valid_loss: 0.28153\n",
            "Validation loss decreased (0.284729 --> 0.281532).  Saving model ...\n",
            "[ 17/20] train_loss: 0.17877 valid_loss: 0.28262\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[ 18/20] train_loss: 0.17028 valid_loss: 0.29468\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[ 19/20] train_loss: 0.16490 valid_loss: 0.29533\n",
            "EarlyStopping counter: 3 out of 20\n"
          ]
        }
      ],
      "source": [
        "batch_size = batch_size\n",
        "n_epochs = num_epochs+10\n",
        "train_loader, test_loader, valid_loader = create_datasets(batch_size)\n",
        "# early stopping patience; how long to wait after last time validation loss improved.\n",
        "patience = 20\n",
        "model, train_loss, valid_loss = train_model(model, batch_size, patience, n_epochs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu4fusfSV8dn"
      },
      "outputs": [],
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1\n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "UdR5z_9PWEVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ad39e1-28d7-45b1-ef4f-2876b65e3c45"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.311435\n",
            "\n",
            "Test Accuracy of     0: 78% (788/1000)\n",
            "Test Accuracy of     1: 97% (976/997)\n",
            "Test Accuracy of     2: 81% (812/999)\n",
            "Test Accuracy of     3: 90% (906/999)\n",
            "Test Accuracy of     4: 78% (789/999)\n",
            "Test Accuracy of     5: 96% (967/997)\n",
            "Test Accuracy of     6: 75% (756/999)\n",
            "Test Accuracy of     7: 97% (970/999)\n",
            "Test Accuracy of     8: 97% (975/997)\n",
            "Test Accuracy of     9: 96% (965/998)\n",
            "\n",
            "Test Accuracy (Overall):    89% ( 8904/ 9984)\n"
          ]
        }
      ],
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "model.eval() # prep model for evaluation\n",
        "for data, target in test_loader:\n",
        "  if len(target.data) != batch_size:\n",
        "    break\n",
        "  data = data.reshape(-1, 28*28).to(device)\n",
        "  target = target.to(device)\n",
        "  # forward pass: compute predicted outputs by passing inputs to the model\n",
        "  output = model(data)\n",
        "  # calculate the loss\n",
        "  loss = criterion(output, target)\n",
        "  # update test loss\n",
        "  test_loss += loss.item()*data.size(0)\n",
        "  # convert output probabilities to predicted class\n",
        "  _, pred = torch.max(output, 1)\n",
        "  # compare predictions to true label\n",
        "  correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "  # calculate test accuracy for each object class\n",
        "  for i in range(batch_size):\n",
        "    label = target.data[i]\n",
        "    class_correct[label] += correct[i].item()\n",
        "    class_total[label] += 1\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "for i in range(10):\n",
        "  if class_total[i] > 0:\n",
        "    print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "    str(i), 100 * class_correct[i] / class_total[i],\n",
        "    np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "  else:\n",
        "    print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "print('\\nTest Accuracy (Overall): %5d%% (%5d/%5d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
        "                                                      np.sum(class_correct), np.sum(class_total)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}